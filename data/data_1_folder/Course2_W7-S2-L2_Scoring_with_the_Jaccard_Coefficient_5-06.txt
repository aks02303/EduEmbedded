As a first simple example of the ranked
retrieval model, let's consider scoring
with the Jaccard coefficient. So the
Jaccard coefficient is a commonly used
measure for the overlap between two sets,
A and B. And what it is, is simply, you
take the number of items in the
intersection of A and B, and you divide it
by the number of items in the union of A
and B. And so if we take the Jaccard
coefficient of a set with itself, then the
set has some size. And then that size will
be also the size of the intersection and the
union. And so the ratio will be one, and
the Jaccard Coefficient is one. If two
sets are disjoint and have no members in
common then the numerator of the Jaccard
coefficient will be zero and so the Jaccard
coefficient is zero. Now the two sets
don't have to be the same size but you
should be able to see that the Jaccard
coefficient will always assign a number
between zero and one, cause at most the
intersection can be as large as the union.
So suppose we decided to make the query
document match score the Jaccard
coefficient computed for the sets of words
the two documents contain. So the idea is
that let's suppose our query is Ides of
March, which has these three words, and
then we have these two documents. So what
we can do is say, so there are three
different words here. And then for
document one, Caesar doesn't occur in it.
Died doesn't occur in it. In doesn't occur
in it. March does occur in it. So the size
of the intersection Is just one word and
the total number of words is six.
If we then do the second document, well, the
doesn't occur in the query, long doesn't
occur in the query, but again March does
occur in the query. So this time, the
Jaccard coefficient of D1, D2, is
going to be one divided by the number of words,
which is this time five. Okay, and
so this document is going to win as having
the higher Jaccard score. Now of course
that difference may not seem very
significant. Essentially this document is
winning here just because it's shorter.
But if we imagined a different example where 
we maybe had the word Ides in the
second document. Then we'd get that the
Jaccard coefficient for it is now two
overlapping words over six. And that maybe
makes more sense to you that you're
getting more overlaps if the Jaccard score
is higher. But this idea that all else being
equal a shorter document should be
preferred is a common one that we'll see
again in IR models. Okay, so is Jaccard
scoring a good idea for a retrieval model?
In general it's not felt to be. It has a
couple of issues. One is that it doesn't
consider term frequency. It just uses the
set of words in the document and ignores
how many times the words occur in a
document. But that's typically not all
the information we want and we'll look at
models in a minute that do deal with term
frequency. There's also a second finer
point, which is that rare terms in a
collection are more informative than
frequent terms when evaluating the, a
query. And that's something that we'll
also want to factor into our models.
There's one other aspect in which the
Jaccard coefficient turns out not to work
very well. And that is, the way in which
it does normalization by dividing through
by the union isn't necessarily quite
right. I mean, in particular, later on in
these segments we'll introduce the idea of
using cosine similarity. And we'll go
through the math of that for the more
general case. And if after you've seen
that you want to kind of come back to this
and work out what the cosine similarity
score is, if you just have a one zero bag
of words and work out a cosine score.
It'll turn out that it's this, which is
like the Jaccard coefficient except that
we've got this slight difference in the
denominator that we're now taking the
square root of the union. And that
actually turns out to be a better form of
length normalization. Okay. So, I
introduced the Jaccard Coefficient just as
a very simple example of a ranked
retrieval model. But I think it was, I
hope it was also a way to show some of the
issues that we need to deal with in a good
retrieval model. How to factor in the
frequency of terms, the rareness of words,
and how to normalize the score for
different document lengths.
