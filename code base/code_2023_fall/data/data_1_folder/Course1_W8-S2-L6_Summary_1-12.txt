So that's basically it. 
What we've seen here, is a way of using 
log-linear models, to construct a very 
different type of parsing model from the 
problistic context-free grammar, style 
models we saw earlier in this class. 
Either of these approaches has its 
strengths and weaknesses. 
Ratnaparkhi's method, is in some sense 
rather simple, all you need to do is 
define these feature vector definitions, 
and you have an approach, you have a 
parser. 
And it's also quite powerful, in that you 
can incorporate quite rich features 
within these feature vector definitions. 
Ratnaparkhi's parser was recently 
successful with accuracy quite close to 
the accuracy for Lexia' piece of cheese, 
as I showed you, earlier in the class. 
More recently, these kind of models have 
been applied to a problem called 
dependency parsing, where, they're 
extremely effective. 
And they produce some of the most 
efficient and most accurate dependency 
parsers. 
And hopefully we'll see some of these 
dependency parsing models next week, so 
you'll find out a little bit more about 
that in the next week of class. 

