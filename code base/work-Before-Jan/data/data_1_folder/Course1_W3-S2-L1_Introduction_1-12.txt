Okay, so in the last segment of the class,
we saw context-free grammars.
And we saw how ambiguity is a very severe
problem in parsing natural languages.
This is the problem where a given sentence
can have several different possible parse
trees under a grammar.
In this next segment we're going to
describe probabilistic context-free
grammars, often abbreviated as PCFGs.
So PCFGS augment context-free grammars by
adding a probability to each rule in the
grammar.
And they thereby assign a probability to
every possible parse tree under the
grammar.
And as we'll see, they allow us a very
direct attack on the ambiguity problem.
In their simplest form, they actually
perform rather poorly as a parsing model.
But we'll see in subsequent lectures in
the class, that with just a few
refinements, they can actually form very
effective models.
So PCFGs are a simple model, they're a
very old model, but they're a crucial
model that forms the basis of many, many,
parsing models now used in natural
language processing.
