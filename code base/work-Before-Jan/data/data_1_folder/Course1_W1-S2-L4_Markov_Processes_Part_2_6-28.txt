>> Okay.
So, we've defined first-order Markov
processes.
We'll now see how to generalize these to
what are called second-order Markov
processes.
And, in fact, this will be a very straight
forward generalization of what I've just
shown you.
So, the task again is to model the joint
distribution over a sequence of n random
variables.
And in a second-order Markov process, we
make the following assumption, that this
joint probability is again a product of
terms.
We have the probability that X1 is equal
to little x1.
We have probability that X2 is equal to x2
,condition on X1 equals x1.
But the, for elements further along in the
sequence, i equals 3 to n, the value for
the ith random variable depends on the
previous two random variables.
So remember, in a first-order Markov
process, we would have had this term alone
being conditioned on.
We now also add the term two positions
back.
So, this in a sense is a slightly more
powerful model, and that it can capture a
broader class of distributions.
We're conditioning on a little bit more
information.
We're essentially just conditioning on the
previous two elements in this sequence
rather than the previous one.
So, if we condition on what the, the
previous element just i minus 1 is called
a first-order process.
You condition on the previous two
elements, is a second-order process.
And you can go further, you can, in fact,
define third order and fourth order of
Markov processes in the natural way.
So, that's essentially it.
That's a second-order Markov process.
To make things a little bit simpler, note
these terms are a little awkward.
To make things a little bit simpler, we're
actually going to write down a
second-order Markov process, as follows.
I now have a product from i equals 1 to n.
And at each point, I have the ith
conditioned on the value at i minus 2 and
also i minus 1.
And I'm now careful to essentially define
a couple of random variables X minus 1 and
X0, essentially at the start of the
sequence, and these random variables
always take the value star.
So, you can think of as always starting
this Markov process with xi sorry, X minus
1 equal to star X0 given star, and then we
have X1.
This next element, maybe that's some word
there.
X2 is then next element and so on and so
on.
Okay.
So, this just makes things slightly
simpler basically from a notational point
of view.
So, up to now, I've assumed that the
length of the sequence, n, is fixed.
But really we'd like to generalize this
kind of model.
So, the length of the sequence, n, is also
a random variable.
What this means is, we'd like to define a
distribution over all possible sequences
where the sequence length can also vary.
And you can see now how we're get, getting
closer and closer to the language modeling
problem because with language models, it's
essential to model a distribution over
sentences where the length of the sentence
can vary.
And there's actually a very simple
solution to this, a direct extension of
second-order Markov processes, or
first-order Markov processes for that
matter.
And we'll essentially just say that the
nth random variable is always equal to
STOP, where STOP is a special symbol.
It's special and that it is not in the
regular vocabulary in the Markov process,
it's not a member of the set v.
Sort of an additional symbol, so it's not
in the set v.
And it's only ever seen at the end of a
sequence.
And then, we can use a Markov process
exactly as before.
We can say that this joint probability is
equal to product of terms, i equals 1 to
n, at each point, we condition the value
of the ith random variable on the previous
two random variables and we are just
assuming that Xn is equal to STOP.
So, we now have a way of writing down the
probability of the sequence, for any
length, we get a distribution of all
length sequences.
Intuitively, what's going on here is that
I have a process where, at each point, I'm
generating the value of the ith random
variable conditioned on the previous two
random variables.
So, you can think of generating a sequence
of random variables in left to right
order.
First x1, then x2, then x3, up to xn.
And at each point, there's a possibility
that this I thread and random variable
will be stop.
And if I see the STOP symbol, I then just
stop and output that sequence as the
output of this, this process, this
sampling process.
A little bit more formally, you can show
that under quite mild conditions we do,
under this addition, under the
stipulation, that this is equal to STOP.
We will have a well-formed distribution
over all possible sequences of varying
length.
And I don't want to go into the details of
that.
But that's a fairly straightforward
application of the theory behind Markov
process to show that we have a well-formed
distribution.
But again, the main thing is just to think
about the intuition, where at each point,
we're generating some symbol, Xi, and if
we ever generate STOP, we immediately
terminate the process.
