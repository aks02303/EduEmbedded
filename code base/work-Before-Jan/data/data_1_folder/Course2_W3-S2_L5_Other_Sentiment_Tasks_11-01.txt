There are other sentiment tasks than just
positive and negative polarity. One
important one, has to do with finding the
sentiment of a, of an individual sentence,
which we're gonna wanna do for finding
aspects or attributes that we talked
about, earlier. So that's the, finding the
target of the sentiment. What it is that
we're, talking about the sentiment about.
So here's a sentence. The food was great,
but the service was awful. This whole
sentence doesn't really have a sentiment.
It has a positive sentiment about food,
and a negative sentiment about service. So
we'd like to be able to deal with this
kind of micro sentiment, where we have a,
we have a sentiment about one attribute,
and a different sentiment about a
different attribute or aspect. So how are
we gonna find the aspect, or attribute, or
sometimes it's called target, of a
sentiment? And I'll show you, an example,
that a way of doing things that was
developed both [inaudible] and by Blair
Goldensohn at all. And the idea is, we
first look through all the reviews, and we
find every highly frequent phrase. So
let's say that the word fish tacos occurs
a lot [inaudible], in. In this particular
restaurant reviews of this restaurant, and
then we mark down, we have filters let's
say we prefer highly frequent phrases if
they occur right after a sentiment word.
So maybe we, very often, see the phrase
great followed by fish tacos or terrible
followed by fish tacos. That suggests that
fish tacos is the, is an aspect, a likely
aspect of a, let's say, a Tacoria. So if
we see great food. A lot. We see food
occurring very often. In, in a. Review and
we see the word great, and terrible, and
awful and before and a lot, we know it's
probably an aspect that people are
applying sentiment for. And this can be
used automatically. Define sentiment for
lots of things. So, Blair Goldensohn used
it, for example, for casino, reviews of
casinos, to find words like casino,
buffet, pool, resort, and beds are the
kind of things people comment about in
reviews on casinos. For a barbe r you
might talk about the experience, or how
good a job it was, or facts about the
haircut. For a department store, you might
talk about Sales, or, or different
departments, or the selection of the
store, things like that. So we can
automatically find the aspect. In other
cases, though, the word that describes the
aspect may not be in the sentence. And so,
for some sentiment topics, like
restaurants or hotels, it's pretty well
understood what the aspects are that
people care about for restaurants.
Restaurants, they tend to care about food,
decor, service, value. And so, for cases
where we know in advance what the frequent
aspects are. Here, we can take a small
corpus of restaurant reviews, and we can
hand label it. We'll just mark every
sentence, Does this sentence talk about
the food, does it talk about the decor, or
is it none of the above? And then we can
just build a classifier, which, given the
sentence. Assigns an aspect to the
sentence. Is this sentence about food? Is
this sentence about decor? Is this
sentence about service, and so on. And it
could be a sentence, or we could assign
that with, you know, with phrases, or
maybe with clauses, with pieces of
sentences. Whichever we'd like to do. So
two ways of finding aspect of a sentiment.
We can automatically find frequent
phrases. So we can find phrases. And then
we can, build up a set of phrases that
occur frequently, and the titles are good
phrases to, to re, to, that we'd like to
know about for this particular product. Or
we can, decide the aspects in advance,
aspects are, are, come in advance, like we
know that they are the restaurants. And
then our job is just to build a classifier
to find them in the reviews so we can
decide if what a person said about the
food is positive or negative. So putting
this all together, this is the Blair
Goldensohn algorithm from Google, we have
a set of reviews. We're gonna extract a
bunch of sentences or phrases. So here's
our extracted sentences or phrases. And
now for each one of them, we're gonna run
our sentiment c lassifier, is the phrase
positive, negative or maybe it's neutral.
Okay? And then for the ones that are, that
have sentiment in them, the ones that are
positive or negative, so like we set out,
we have sentiments and phrases with
sentiment, plus minus, minus plus, plus
minus, and so on. We're going to extract
the aspects of these. So is this about
food? Is it about, is it about, decor?
What's the sentence about? So now we have
plus food. And now we have. Minus decor,
minus service, and so on for each sentence
or phrase, we have both a sentiment and an
aspect. Now we aggregate these together,
and produce a final summary. And here's an
example of what you might get as the final
summary. So maybe for a hotel, for rooms,
we might get that this sentence, the room
was clean and everything worked fine.
Positive sentiment. Another positive
sentiment. Here's an example of negative
sentiment. So, we first figure out that
worst is a negative sentiment. And then we
might ex, extract from somewhere in here
that there's some mention of rooms. And
similarly for service, we might see,
service gives new meaning to slow, and
that's a negative. We made some
simplifications in the base line method we
gave for sentiment classification. We
assumed that the classes, positive and
negative, occurred with equal frequency.
And that's, of course, not usually true in
the real world. And it turns out that when
the classes are not balanced. You can't
use accuracies as an evaluation. And the F
score, can deal well. And when evaluating
classes where there's many more positive
than negative, or maybe there's many more
negative than positive reviews. It turns
out that this. The, there's a severe
imbalance in class frequencies, that can
actually degrade the classifier
performance. And there are two standard
things we do to deal with that. One is, we
just re-sample before we train. So for
example, if one class has, a million
reviews, and one class has, 10,000
reviews, then, we might just dance down
sample and take only ten to the fourth of
these re views. To match with these
reviews. Instead of re-sampling, we can
use cost sensitive learning. Cost
sensitive learning we take, we actually
change the classifier, and we tell the
classifier, don't, even though this one,
you've seen a lot more of this frequent
thing penalize it for mis-classifying the
really rare thing, and so that'll force it
to focus a little more on the rare things,
then on the very frequent things. So two
things you can do to deal with the
imbalance frequency problem that often
occur in real classes. We also in our, in
our base, baseline algorithm, made the
simplifying assumption that, sentiment was
a binary problem, positive or negative. So
how do we deal with five stars, or seven
stars, or ten stars? There are two ways we
can do this. We can map, onto a binary
class, we can say things that are more
than 3.5 stars are positive, or less than
3.5 are negative. Or we can take the
average of all the data. We can Z score.
We can do various ways of, of drawing a
boundary between positive things and
negative things. Or we can. Actually
attack the seven, one to seven
classification task directly, by using
linear ordinal regression or specialized
models like metric labeling that's used by
Pang and Lee. So again, we can either Down
sample and just do binary classification,
or we can use a more advanced method of
classification that let's us predict an
ordinal value or, or a real valued number.
So in summary Sentiment generally modeled
as a classification task. Polarity often
with binary. Less often, with some kind of
ordinal or linear valued label. And,
negation, a very important feature to use.
For lots of tasks, using all the words in
naive bays seems to work well. For other
tasks, using subsets of words may help.
And we can either use hand built polarity
lexicons. Or, for tasks for which the
polarity lexicons seem inappropriate, we
can induce lexicons using semi-supervised
learning from some hand built seeds. Now
remember that. Sentiment is really just
one of many kinds of affective state. It's
a, it's a kind of attitude classification,
but. There's lots of other kinds of
effective state classification that come
up. And they're computational problems
that are very similar to sentiment
analysis. So to look at some of them for
emotions, we might want to detect annoyed
callers to some dialogue system. So it's
detecting the emotion of annoyance. Or
detect confused or frustrated students in
online tutorial, versus confident
students. For longer-term moods, we might
wanna find traumatized or depressed people
like writers of some, blog or text. In
conversations, we might wanna detect if
someone's friendly, or unfriendly. In very
long-term personality traits, we might
want to detect extroverts or introverts
for building dialog systems that can
communicate better with extroverts or
introverts. And there's lot of research
actually on all of these tasks we'll just
show you one of them, which is a task
we've worked on here at Stanford, which is
detection of friendliness. So, friendly
speakers use, it turns out, use
collaborative conversational style. So we
built classifiers that look at features
like how often someone laughs, or how
often they use negative emotional words.
Or how frequently they use phrases like
that's too bad that indicate sympathy or
agreement. I think so, too. So the more
friendly someone is, the more likely they
are to use sympathetic words or agreement,
or the less likely they are to use a hedge
like kind of or sort of. And we've shown
that these classifiers help in, we've
looked at the task of detecting how
friendly someone is or how flirtatious
someone is in speed dates. And we've found
that these kind of, features help
detecting friendliness. So, simple lexical
features, like words and phrases, and
where we have speech, speech features like
[inaudible] or pitch. All of these can
help in detecting sentiment, simple
polarity, and much more rich effective
meaning of all sorts of kinds.
